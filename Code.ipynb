{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)\n",
    "#subset=['Text'] searches for duplicates only in the column with name Text(Last column)\n",
    "#inplace=true will cause all the rows which have same text value to be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)\n",
    "#this is the instruction to delete all rows with atleast one NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88421 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      "Id                        88421 non-null int64\n",
      "ProductId                 88421 non-null object\n",
      "UserId                    88421 non-null object\n",
      "ProfileName               88421 non-null object\n",
      "HelpfulnessNumerator      88421 non-null int64\n",
      "HelpfulnessDenominator    88421 non-null int64\n",
      "Score                     88421 non-null int64\n",
      "Time                      88421 non-null int64\n",
      "Summary                   88421 non-null object\n",
      "Text                      88421 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove unnecessary symbols we will define a dictionary for expanding the contractions\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\DRISHTI\n",
      "[nltk_data]     MAMTANI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that \n",
    "#a search engine has been programmed to ignore, both when indexing entries for searching and \n",
    "#when retrieving them as the result of a search query.\n",
    "#To check the list of stopwords we use the following instruction\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function for test cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,num):\n",
    "    String1 = text.lower() #converting to lower case. After this the complete review will be in lower case\n",
    "    String1 = BeautifulSoup(String1, \"lxml\").text \n",
    "    #Beautiful Soup is a Python library for pulling data out of HTML and XML files. It is used for tasks like extracting the \n",
    "    #entire text from a page, extracting all URLs found in a page\n",
    "    #We create a BeautifulSoup object by passing two arguments:newString(raw HTML content) and lxml(HTML parser we want to use)\n",
    "    String1 = re.sub(r'\\([^)]*\\)', '', String1)\n",
    "    #The re.sub() function in the re module can be used to replace substrings. \n",
    "    #The syntax for re.sub() is re.sub(pattern,repl,string). \n",
    "    #That will replace the matches in string with repl. \n",
    "    String1 = re.sub('\"','', String1)\n",
    "    String1 = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in String1.split(\" \")]) \n",
    "    #The join() method is a string method and returns a string in which the elements of sequence have been joined by str separator.\n",
    "    #Here we join with an empty string.\n",
    "    #The above instruction removes contraction from the string.\n",
    "    String1 = re.sub(r\"'s\\b\",\"\",String1)\n",
    "    String1 = re.sub(\"[^a-zA-Z]\", \" \", String1) \n",
    "    String1 = re.sub('[m]{2,}', 'mm', String1)\n",
    "    #removes the stopwords\n",
    "    #tokens will be a list\n",
    "    if(num==0):\n",
    "        #for text remove the stop_words\n",
    "        tokens = [w for w in String1.split() if not w in stop_words]\n",
    "    else:\n",
    "        #for summary stop words cannot be removed because the summary is already small. So just take all words in summary as tokens\n",
    "        tokens=String1.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        #for each token if length of the token is less than one then eliminate the token/word \n",
    "        if len(i)>1:                                                \n",
    "            long_words.append(i)  \n",
    "    #join will convert the list back to string and strip() will remove leading spaces if any.\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the function text_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample string to understand the use of contraction mapping and join function\n",
    "string=\"ABC ain't def ain't\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC', 'is not', 'def', 'is not']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the words of a sentence at the \" \" (string.split(\" \"))\n",
    "#check each word if it is the key of the dictionary contraction_mapping then replace the key by the value\n",
    "#if not then keep the word as it is\n",
    "#string will be list of resultant words\n",
    "string =[contraction_mapping[t] if t in contraction_mapping else t for t in string.split(\" \")]\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC is not def is not'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get the string back from list of words\n",
    "string=' '.join(string) \n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC is not def is not'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join the list of words so obtanined with an empty string to convert back to string\n",
    "string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in string.split(\" \")]) \n",
    "string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC is not def is not'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC', 'is', 'not', 'def', 'is', 'not']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.split() #string bydefault splits at spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC', 'def']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This gives words which are not stopwords\n",
    "tokens = [w for w in string.split() if not w in stop_words]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining tokens to understand elimination of short words\n",
    "tokens=['I','am','a','girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'girl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_words=[]\n",
    "for i in tokens :\n",
    "    #Initially long words is a empty list\n",
    "    #Examine each token and if its length is greater than 1 then include it in the long_word list. \n",
    "    #In this way all the short words with length 0 or 1 are removed\n",
    "    if len(i)>1:                                                \n",
    "        long_words.append(i)  \n",
    "long_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am girl'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am girl'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(long_words).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "#cleaned_text is an empty string intially. For each entry i.e. row the text column value is \n",
    "#taken and cleaned by the function text_cleaner defined above. The cleaned text is added in the cleaned_text list.\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same function is called for the Summary column as well and in similar manner cleanned_summary list is generated.\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding two new columns namely cleaned_text and cleaned_summary in the data\n",
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop ' '(Empty) rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first replace blank spaces with NaN and then drop rows with NaN.\n",
    "#This can be called a trick to drop ' ' by using dropna\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Understanding the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "for i in data['cleaned_text']:\n",
    "    #for each entry in cleaned_text the number of words are counted in the entry and the count is appended to text_word_count list \n",
    "    text_word_count.append(len(i.split()))\n",
    "for i in data['cleaned_summary']:\n",
    "    #for each entry in cleaned_summary the number of words are counted in the entry and the count is appended to summary_word_count list  \n",
    "    summary_word_count.append(len(i.split()))\n",
    "#A dataframe with two columns is made. 1st column has entries of text_word_count and 2nd has entries of summart_word_count \n",
    "df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  summary\n",
       "0    23        4\n",
       "1    18        3\n",
       "2    39        4\n",
       "3    17        2\n",
       "4    13        2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #by default 5 entries are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the histogram for the dataframe\n",
    "#Histogram plots the graph between values and frequencies\n",
    "df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out the percentage of summaries below length=8,length=9 and length=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the appropriate max summary length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424926998211739\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 8 then increement count\n",
    "#In this way count will have the count of cleaned summaries with number of words less than or equal to 8.\n",
    "count=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9650383683817371\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 9 then increement count\n",
    "#In this way count will have the count of cleaned summaries with number of words less than or equal to 9.\n",
    "count=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=9):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788690947778256\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#for each entry in cleaned summary, split the cleaned summary at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 10 then increement count\n",
    "#In this way count will have the count of cleaned summaries with number of words less than or equal to 10.\n",
    "count=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=10):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fix the max cleaned summary length to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the appropriate max text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34857505036557485\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 20 then increement count\n",
    "#In this way count will have the count of cleaned texts with number of words less than or equal to 20.\n",
    "count=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=20):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4584851845983204\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 25 then increement count\n",
    "#In this way count will have the count of cleaned texts with number of words less than or equal to 25.\n",
    "count=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=25):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232541820404283\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 35 then increement count\n",
    "#In this way count will have the count of cleaned texts with number of words less than or equal to 35.\n",
    "count=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=35):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7336509948615796\n"
     ]
    }
   ],
   "source": [
    "#initialize count with value 0\n",
    "#foe each entry in cleaned text, split the cleaned text at spaces to find number of words and if the no. of word\n",
    "#are less than or equal to 45 then increement count\n",
    "#In this way count will have the count of cleaned texts with number of words less than or equal to 45.\n",
    "count=0\n",
    "for i in data['cleaned_text']:\n",
    "    if(len(i.split())<=45):\n",
    "        count=count+1\n",
    "print(count/len(data['cleaned_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fix the max text length as 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now selecting those entries in which cleaned text length is less than equal to 45 and cleaned summary length is less than equal to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_summary_len=10\n",
    "max_text_len=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making array of cleaned text entries and cleaned summary entries\n",
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "#short_text and short_summary are initially empty but will contain all the text and summary entries which fall in the desired range\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    #For all entries if the cleaned_summary has no. of words <=max summary length which is equal to 10 \n",
    "    #and cleaned_text has no. of words <=max text length which is equal to 45 add such entries to the lists short_text and short_summary\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "#create a dataframe to store the results of short_text and short_summary    \n",
    "df1=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "      <td>good quality dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
       "      <td>not as advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
       "      <td>delight says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
       "      <td>cough medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
       "      <td>great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better   \n",
       "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo   \n",
       "2  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...   \n",
       "3                                                                              looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal   \n",
       "4                                                                                                                      great taffy great price wide assortment yummy taffy delivery quick taffy lover deal   \n",
       "\n",
       "                 summary  \n",
       "0  good quality dog food  \n",
       "1      not as advertised  \n",
       "2    delight says it all  \n",
       "3         cough medicine  \n",
       "4            great taffy  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the start and end token to each summary. This can be done using lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will replace each summary with 'starttoken' as start token concatenated with summary concatenated with 'endtoken' as end token \n",
    "#Be sure that the chosen special tokens never appear in the summary\n",
    "df1['summary'] = df1['summary'].apply(lambda x : 'starttoken '+ x + ' endtoken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splitting data into training and testing sets. Take 90% of the dataset as the training data and evaluate the performance on the remaining 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn is used to perform the split. This is standard technique to split the dataset.Test size is set to 0.1 i.e. 10%.\n",
    "#x variable is text\n",
    "#y variable is summary\n",
    "#df['text'] and df['summary'] contain respective reviews and summaries in form of array\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.array(df1['text']),np.array(df1['summary']),test_size=0.1,random_state=0,shuffle=True)\n",
    "#xtrain,x_test,y_train,y_test all are numpy arrays containing reviews and summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "t = Tokenizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x217f2674860>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n",
    "#Output would be  <keras_preprocessing.text.Tokenizer at 0x217e980deb8>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing x_train. First x_train which is a numpy array is converted to list\n",
    "t.fit_on_texts(list(x_train))\n",
    "#fit_on_texts Updates internal vocabulary based on a list of texts. \n",
    "#This method creates the vocabulary index based on word frequency. \n",
    "#So if you give it something like, \"The cat sat on the mat.\" \n",
    "#It will create a dictionary s.t. word_index[\"the\"] = 1; \n",
    "#word_index[\"cat\"] = 2 it is word -> index dictionary so every word gets a unique integer value. \n",
    "#0 is reserved for padding. \n",
    "#So lower integer means more frequent word (often the first few are stop words because they appear a lot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rarewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19220\n",
      "32663\n",
      "% of rare words in vocabulary: 58.843339558521876\n",
      "Total Coverage of rare words: 1.749112399187831\n"
     ]
    }
   ],
   "source": [
    "#Rare words are those words which do not appear too often\n",
    "#Defining the threshold as 3. If the words apear less than thrice then the word are rare words.\n",
    "threshold=3\n",
    "#count has count of rare words\n",
    "count=0\n",
    "#totalcount has the count of total number of words i.e. size of vocabulary\n",
    "totalcount=0\n",
    "#frequency has total frequency of all the rare words\n",
    "frequency=0\n",
    "#totalfrequency has the sum of all frequencies of all words\n",
    "totalfrequency=0\n",
    "#t.word_counts.items() will give items of ordered dictionary i.e.  'key' and 'value' pair. key being the word and value being the number of times it ocuured.\n",
    "#odict_items([('love', 45148), ('raspberry', 1096), ('shortbread', 276), ('cookies', 6596), ('easy', 10588), ('find', 21556), ....\n",
    "for key,value in t.word_counts.items():\n",
    "    #accessing each key value pair\n",
    "    #totalcount is increemented by 1 as the word encountered is a new word add totalcount by 1\n",
    "    totalcount=totalcount+1\n",
    "    #totalfrequency is increemneted by value \n",
    "    totalfrequency=totalfrequency+value\n",
    "    #if value is less than threshold than it is rare word and count is incremented by 1 and frequency by value. \n",
    "    if(value<threshold):\n",
    "        count=count+1\n",
    "        frequency=frequency+value\n",
    "print(count)\n",
    "print(totalcount)\n",
    "# %of rare words is (number of rare words divided by total number of words) multiplied by 100 i.e. (count divided by totalcount) multiplied by 100\n",
    "print(\"% of rare words in vocabulary:\",(count/totalcount)*100)\n",
    "# coverage of rare words is (frequency divided by total frequency) multiplied by 100\n",
    "print(\"Total Coverage of rare words:\",(frequency/totalfrequency)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "#totalcount-count is number of common words\n",
    "#Only common words will be remembered\n",
    "x_tokenizer = Tokenizer(num_words=totalcount-count)\n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "#x_tokenizer.word_index will give\n",
    "#{'like': 1,'good': 2, 'great': 3,'taste': 4, 'product': 5,'love': 6,'one': 7,....\n",
    "#This means like appers is the most common word followed by good then great and so on\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_train_sequence    =   x_tokenizer.texts_to_sequences(x_train)\n",
    "#only common words will be remembered\n",
    "x_test_sequence   =   x_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "#pad_sequences is used to ensure that all sequences in a list have the same length.\n",
    "#By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
    "#Here zeros are padded at the end\n",
    "x_train   =   pad_sequences(x_train_sequence,  maxlen=max_text_len,padding='post')\n",
    "x_test   =   pad_sequences(x_test_sequence, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6,  827, 2254, ...,    0,    0,    0],\n",
       "       [1795, 1072,   66, ...,    0,    0,    0],\n",
       "       [  34,   57, 4240, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   3,   11,  216, ...,    0,    0,    0],\n",
       "       [  31,  377,  591, ...,    0,    0,    0],\n",
       "       [   2,  362,    5, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13444"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For understanding Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "texts = ['a a a', 'b b b b b', 'c c c c c c c','ddd','aa a','aa aa']\n",
    "#'a a a' is a string with 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=4)\n",
    "#num_words: the maximum number of words to keep, based on word frequency. \n",
    "#Only the most common num_words-1 words will be kept.\n",
    "#Tokenizer will use only three most common words and at the same time, it will keep the counter of all words - even when it's obvious that it will not use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 1, 'b': 2, 'a': 3, 'aa': 4, 'ddd': 5}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "#c is the most common word so will get the value 1.\n",
    "#b will get value 2\n",
    "#a will get 3\n",
    "#aa will get 4\n",
    "#ddd will get 5\n",
    "#More times a number appears lesser will be its key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 3], [2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1], [], [3], []]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(texts)\n",
    "#only c,b,and a will be remembered\n",
    "#See \"aa a\" i.e. 4th index only a is remembered and aa is not so only 3 is the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "t1= Tokenizer()   \n",
    "t1.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22606\n",
      "32663\n",
      "% of rare words in vocabulary: 69.20980926430518\n",
      "Total Coverage of rare words: 2.619131342233918\n"
     ]
    }
   ],
   "source": [
    "#Doing the similar thing with summary\n",
    "#Threshold is set to 5\n",
    "threshold=5\n",
    "count=0\n",
    "totalcount=0\n",
    "frequency=0\n",
    "totalfrequency=0\n",
    "\n",
    "for key,value in t.word_counts.items():\n",
    "    totalcount=totalcount+1\n",
    "    totalfrequency=totalfrequency+value\n",
    "    if(value<threshold):\n",
    "        count=count+1\n",
    "        frequency=frequency+value\n",
    "print(count)\n",
    "print(totalcount)    \n",
    "print(\"% of rare words in vocabulary:\",(count/totalcount)*100)\n",
    "print(\"Total Coverage of rare words:\",(frequency/totalfrequency)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=totalcount-count) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_train_sequence=y_tokenizer.texts_to_sequences(y_train) \n",
    "y_test_sequence=y_tokenizer.texts_to_sequences(y_test) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train=pad_sequences(y_train_sequence, maxlen=max_summary_len, padding='post')\n",
    "y_test=pad_sequences(y_test_sequence, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc=y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10058"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57652, 57652)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of times startoken appears should be equal to length of training data \n",
    "y_tokenizer.word_counts['starttoken'],len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting those rows which only contain start and end token\n",
    "empty=[]\n",
    "#Checking each element of y train. Each element of y train is a list in itself.\n",
    "for i in range(len(y_train)):\n",
    "    count=0\n",
    "    for j in y_train[i]:\n",
    "        #checking each element in one element of y_train\n",
    "            count=count+1\n",
    "    if(count==2):\n",
    "        #if there are only 2 non zero elements that is start and end token then the list is actualy empty and append that index \n",
    "        #in empty list so that we can delete those rows\n",
    "        empty.append(i)\n",
    "\n",
    "#Deleting x and y  for those indices present in empty list that is those rows which only have start and end token\n",
    "y_train=np.delete(y_train,empty, axis=0)\n",
    "x_train=np.delete(x_train,empty, axis=0)\n",
    "#Axis is 0 because rows have to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting those rows which only contain start and end token\n",
    "empty=[]\n",
    "for i in range(len(y_test)):\n",
    "    count=0\n",
    "    for j in y_test[i]:\n",
    "        if j!=0:\n",
    "            count=count+1\n",
    "    if(count==2):\n",
    "        empty.append(i)\n",
    "\n",
    "y_test=np.delete(y_test,empty, axis=0)\n",
    "x_test=np.delete(x_test,empty, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "\n",
    "#Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "\n",
    "#Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
    "\n",
    "#Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 45)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 100)      1344400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    1005800     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer [(None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 10058)  6044858     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,980,158\n",
      "Trainable params: 10,980,158\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "#If the validation loss increases then stop the model early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57652 samples, validate on 6324 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Public\\A\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "57652/57652 [==============================] - 1909s 33ms/sample - loss: 2.7394 - val_loss: 2.4718\n",
      "Epoch 2/50\n",
      "57652/57652 [==============================] - 1901s 33ms/sample - loss: 2.4530 - val_loss: 2.3258\n",
      "Epoch 3/50\n",
      "57652/57652 [==============================] - 1904s 33ms/sample - loss: 2.3266 - val_loss: 2.2388\n",
      "Epoch 4/50\n",
      "57652/57652 [==============================] - 1918s 33ms/sample - loss: 2.2466 - val_loss: 2.1732\n",
      "Epoch 5/50\n",
      "57652/57652 [==============================] - 1917s 33ms/sample - loss: 2.1874 - val_loss: 2.1311\n",
      "Epoch 6/50\n",
      "57652/57652 [==============================] - 1917s 33ms/sample - loss: 2.1383 - val_loss: 2.1091\n",
      "Epoch 7/50\n",
      "57652/57652 [==============================] - 1900s 33ms/sample - loss: 2.0997 - val_loss: 2.0775\n",
      "Epoch 8/50\n",
      "57652/57652 [==============================] - 1903s 33ms/sample - loss: 2.0671 - val_loss: 2.0622\n",
      "Epoch 9/50\n",
      "57652/57652 [==============================] - 2231s 39ms/sample - loss: 2.0389 - val_loss: 2.0443\n",
      "Epoch 10/50\n",
      "57652/57652 [==============================] - 2469s 43ms/sample - loss: 2.0145 - val_loss: 2.0291\n",
      "Epoch 11/50\n",
      "57652/57652 [==============================] - 2769s 48ms/sample - loss: 1.9881 - val_loss: 2.0256\n",
      "Epoch 12/50\n",
      "57652/57652 [==============================] - 2792s 48ms/sample - loss: 1.9682 - val_loss: 2.0089\n",
      "Epoch 13/50\n",
      "57652/57652 [==============================] - 21167s 367ms/sample - loss: 1.9474 - val_loss: 2.0056\n",
      "Epoch 14/50\n",
      "57652/57652 [==============================] - 1866s 32ms/sample - loss: 1.9287 - val_loss: 1.9992\n",
      "Epoch 15/50\n",
      "57652/57652 [==============================] - 1861s 32ms/sample - loss: 1.9123 - val_loss: 1.9930\n",
      "Epoch 16/50\n",
      "57652/57652 [==============================] - 1864s 32ms/sample - loss: 1.8998 - val_loss: 1.9890\n",
      "Epoch 17/50\n",
      "57652/57652 [==============================] - 1870s 32ms/sample - loss: 1.8858 - val_loss: 1.9906\n",
      "Epoch 18/50\n",
      "57652/57652 [==============================] - 1877s 33ms/sample - loss: 1.8715 - val_loss: 1.9820\n",
      "Epoch 19/50\n",
      "57652/57652 [==============================] - 1888s 33ms/sample - loss: 1.8591 - val_loss: 1.9787\n",
      "Epoch 20/50\n",
      "57652/57652 [==============================] - 1887s 33ms/sample - loss: 1.8469 - val_loss: 1.9811\n",
      "Epoch 21/50\n",
      "57652/57652 [==============================] - 1882s 33ms/sample - loss: 1.8352 - val_loss: 1.9758\n",
      "Epoch 22/50\n",
      "57652/57652 [==============================] - 1882s 33ms/sample - loss: 1.8234 - val_loss: 1.9721\n",
      "Epoch 23/50\n",
      "57652/57652 [==============================] - 1885s 33ms/sample - loss: 1.8106 - val_loss: 1.9717\n",
      "Epoch 24/50\n",
      "57652/57652 [==============================] - 1884s 33ms/sample - loss: 1.8046 - val_loss: 1.9681\n",
      "Epoch 25/50\n",
      "57652/57652 [==============================] - 1882s 33ms/sample - loss: 1.7964 - val_loss: 1.9695\n",
      "Epoch 26/50\n",
      "57652/57652 [==============================] - 1879s 33ms/sample - loss: 1.7888 - val_loss: 1.9695\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x217833c9048>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21789675748>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "#As it is visible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
